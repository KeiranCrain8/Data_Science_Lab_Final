{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breakout_DQN_tf_agents_.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cOD8sFlxdEH",
        "colab_type": "code",
        "outputId": "a5d4ef90-bed1-40ba-88cb-239840111a41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!sudo apt-get install -y xvfb ffmpeg\n",
        "!pip install 'gym[all]'\n",
        "!pip install 'imageio==2.4.0'\n",
        "!pip install PILLOW\n",
        "!pip install 'pyglet==1.3.2'\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install --upgrade tensorflow-probability\n",
        "!pip install tf-agents"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.6-0ubuntu0.18.04.1).\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.4).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n",
            "Requirement already satisfied: gym[all] in /usr/local/lib/python3.6/dist-packages (0.17.1)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[all]) (1.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[all]) (1.12.0)\n",
            "Collecting pyglet<=1.5.0,>=1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/ca/20aee170afe6011e295e34b27ad7d7ccd795faba581dd3c6f7cec237f561/pyglet-1.5.0-py2.py3-none-any.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[all]) (1.18.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym[all]) (1.4.1)\n",
            "Collecting mujoco-py<2.0,>=1.50; extra == \"all\"\n",
            "  Using cached https://files.pythonhosted.org/packages/cf/8c/64e0630b3d450244feef0688d90eab2448631e40ba6bdbd90a70b84898e7/mujoco-py-1.50.1.68.tar.gz\n",
            "Requirement already satisfied: Pillow; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from gym[all]) (7.0.0)\n",
            "Requirement already satisfied: box2d-py~=2.3.5; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from gym[all]) (2.3.8)\n",
            "Requirement already satisfied: opencv-python; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from gym[all]) (4.1.2.30)\n",
            "Requirement already satisfied: atari-py~=0.2.0; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from gym[all]) (0.2.6)\n",
            "Requirement already satisfied: imageio; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from gym[all]) (2.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[all]) (0.16.0)\n",
            "Requirement already satisfied: glfw>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from mujoco-py<2.0,>=1.50; extra == \"all\"->gym[all]) (1.11.0)\n",
            "Requirement already satisfied: Cython>=0.27.2 in /usr/local/lib/python3.6/dist-packages (from mujoco-py<2.0,>=1.50; extra == \"all\"->gym[all]) (0.29.17)\n",
            "Requirement already satisfied: cffi>=1.10 in /usr/local/lib/python3.6/dist-packages (from mujoco-py<2.0,>=1.50; extra == \"all\"->gym[all]) (1.14.0)\n",
            "Requirement already satisfied: lockfile>=0.12.2 in /usr/local/lib/python3.6/dist-packages (from mujoco-py<2.0,>=1.50; extra == \"all\"->gym[all]) (0.12.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.10->mujoco-py<2.0,>=1.50; extra == \"all\"->gym[all]) (2.20)\n",
            "Building wheels for collected packages: mujoco-py\n",
            "  Building wheel for mujoco-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for mujoco-py\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for mujoco-py\n",
            "Failed to build mujoco-py\n",
            "Installing collected packages: pyglet, mujoco-py\n",
            "  Found existing installation: pyglet 1.3.2\n",
            "    Uninstalling pyglet-1.3.2:\n",
            "      Successfully uninstalled pyglet-1.3.2\n",
            "    Running setup.py install for mujoco-py ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-3mfvip0k/mujoco-py/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-3mfvip0k/mujoco-py/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-rki5akbl/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n",
            "Requirement already satisfied: imageio==2.4.0 in /usr/local/lib/python3.6/dist-packages (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio==2.4.0) (1.18.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio==2.4.0) (7.0.0)\n",
            "Requirement already satisfied: PILLOW in /usr/local/lib/python3.6/dist-packages (7.0.0)\n",
            "Collecting pyglet==1.3.2\n",
            "  Using cached https://files.pythonhosted.org/packages/1c/fc/dad5eaaab68f0c21e2f906a94ddb98175662cc5a654eee404d59554ce0fa/pyglet-1.3.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet==1.3.2) (0.16.0)\n",
            "\u001b[31mERROR: gym 0.17.1 has requirement pyglet<=1.5.0,>=1.4.0, but you'll have pyglet 1.3.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pyglet\n",
            "  Found existing installation: pyglet 1.5.0\n",
            "    Uninstalling pyglet-1.5.0:\n",
            "      Successfully uninstalled pyglet-1.5.0\n",
            "Successfully installed pyglet-1.3.2\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.6/dist-packages (0.2.5)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.6/dist-packages (from pyvirtualdisplay) (0.3)\n",
            "Requirement already up-to-date: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (0.10.0rc0)\n",
            "Requirement already satisfied, skipping upgrade: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability) (0.3.3)\n",
            "Requirement already satisfied: tf-agents in /usr/local/lib/python3.6/dist-packages (0.4.0)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (0.9.0)\n",
            "Requirement already satisfied: tensorflow-probability>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (0.10.0rc0)\n",
            "Requirement already satisfied: gin-config==0.1.3 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (0.1.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (1.18.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.8.0->tf-agents) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.8.0->tf-agents) (4.4.2)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.8.0->tf-agents) (0.3.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhMO-SN0xsiP",
        "colab_type": "code",
        "outputId": "ed69f31b-1878-4fcd-a67d-7ee292315caf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!apt-get install x11-utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "x11-utils is already the newest version (7.7+3build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQUNPbdGxwEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import base64\n",
        "import imageio\n",
        "import IPython\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import pyvirtualdisplay\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.drivers import dynamic_step_driver\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.eval import metric_utils\n",
        "from tf_agents.metrics import tf_metrics\n",
        "from tf_agents.networks import q_network\n",
        "from tf_agents.policies import random_tf_policy\n",
        "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
        "from tf_agents.trajectories import trajectory\n",
        "from tf_agents.utils import common"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMYpiDcQx3Bi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.compat.v1.enable_v2_behavior()\n",
        "\n",
        "# Set up a virtual display for rendering OpenAI gym environments.\n",
        "display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_32lUYwx7Bq",
        "colab_type": "code",
        "outputId": "59d3ecdb-a337-4772-c9fd-6eb050072273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.version.VERSION"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0-rc4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTTdrfWIFqM0",
        "colab_type": "text"
      },
      "source": [
        "**Environment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o0r2mPxyBZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env_name = 'BreakoutDeterministic-v4'\n",
        "env = suite_gym.load(env_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a8XNGuAyDwX",
        "colab_type": "code",
        "outputId": "4753b632-0677-449d-a7e3-55eb65038911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "#@test {\"skip\": true}\n",
        "env.reset()\n",
        "PIL.Image.fromarray(env.render())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKAAAADSCAIAAABCR1ywAAACu0lEQVR4nO3dsW0TYRiA4QS5RkxARcEIEQNYLpjGEzCBx0AMQGGloEQZBlEgRJEiygL+IZZ9d/bL85Sn090vvfl8v+SzcnMDAMDZ3c55s91u989zttvtbOcfa+rrj+51yjVfnWMxXK7VUjeec1Jfcv6xzjWpUzPBcYtN8LUbfSpc2mSb4DgTfITRdE7xjD8XExy32AQf+1c/9flLXXNqJhjgYt1e43OFl/MMjhM4TuA4geMEjhM4TuA4geMEjhM4TuA4geMEjhM4bvjKzqW9/snfjb72NcFxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdw3PDF94fNZs51cKLvg+MmOE7gOIHjBI4TOG64i35692vOdTARExwncJzAcQLHCRw33EX/fP1nznUwERMcJ3CcwHECxwkcN95Fv3+ccx2c6sfhwyY4TuA4geMEjhM4briL/vz0ds51cKL14LgJjhM4TuA4geMEjhvuoh+/fJpxGZxsffj3hSY4TuA4geMEjhM4briL/ra/m3MdnOjj2j+n/C8JHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdwnMBxAscJHCdw3Orrm99Lr+E6PGw2R51/t99PtJKDPtzfHzxuguMEjhM4brX0Aq7GzM/UczHBcSY44ko/YAAAAAAAAFjUMyEkRxlHStXAAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=160x210 at 0x7EFEF91EB400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaDhUe3dHfc5",
        "colab_type": "text"
      },
      "source": [
        "Showing observation, reward, and action specs of the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnW0iDw40FxC",
        "colab_type": "code",
        "outputId": "6c43e963-44d6-467e-b0cd-6528aa067af8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Observation Spec:')\n",
        "print(env.time_step_spec().observation)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation Spec:\n",
            "BoundedArraySpec(shape=(210, 160, 3), dtype=dtype('uint8'), name='observation', minimum=0, maximum=255)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05hCaUJt0HUM",
        "colab_type": "code",
        "outputId": "892a09a4-3986-49d9-ce5f-e49ef9059155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Reward Spec:')\n",
        "print(env.time_step_spec().reward)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reward Spec:\n",
            "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyW-rFjX0K19",
        "colab_type": "code",
        "outputId": "4df703b8-a4e8-43a2-d2fd-fc9b0466b0ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Action Spec:')\n",
        "print(env.action_spec())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Action Spec:\n",
            "BoundedArraySpec(shape=(), dtype=dtype('int64'), name='action', minimum=0, maximum=3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sZqvWOM0NSQ",
        "colab_type": "code",
        "outputId": "a0885059-62d3-48c5-c197-44e5abe7a217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "time_step = env.reset()\n",
        "print('Time step:')\n",
        "print(time_step)\n",
        "\n",
        "action = np.array(1, dtype=np.int32)\n",
        "\n",
        "next_time_step = env.step(action)\n",
        "print('Next time step:')\n",
        "print(next_time_step)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time step:\n",
            "TimeStep(step_type=array(0, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array([[[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]]], dtype=uint8))\n",
            "Next time step:\n",
            "TimeStep(step_type=array(1, dtype=int32), reward=array(0., dtype=float32), discount=array(1., dtype=float32), observation=array([[[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]],\n",
            "\n",
            "       [[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]]], dtype=uint8))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9H9P5tUHowJ",
        "colab_type": "text"
      },
      "source": [
        "Converting environment to Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TGwn30dyFez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_py_env = suite_gym.load(env_name)\n",
        "eval_py_env = suite_gym.load(env_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xskfFhGyO1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
        "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj0WGc6nH3u-",
        "colab_type": "text"
      },
      "source": [
        "**Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4e9YWdCx8xF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_iterations = 20000 # @param {type:\"integer\"}\n",
        "\n",
        "initial_collect_steps = 1000  # @param {type:\"integer\"} \n",
        "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "\n",
        "batch_size =   64# @param {type:\"integer\"}\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
        "eval_interval =   1000# @param {type:\"integer\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehLCq3JZyR3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fc_layer_params = (100,)\n",
        "\n",
        "q_net = q_network.QNetwork(\n",
        "    train_env.observation_spec(),\n",
        "    train_env.action_spec(),\n",
        "    fc_layer_params=fc_layer_params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vye11hnDyTiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "train_step_counter = tf.Variable(0)\n",
        "\n",
        "agent = dqn_agent.DqnAgent(\n",
        "    train_env.time_step_spec(),\n",
        "    train_env.action_spec(),\n",
        "    q_network=q_net,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter)\n",
        "\n",
        "agent.initialize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS-FcTYJyYEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_policy = agent.policy\n",
        "collect_policy = agent.collect_policy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A4tf-70yb9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
        "                                                train_env.action_spec())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_qHQqgj0yCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_environment = tf_py_environment.TFPyEnvironment(\n",
        "    suite_gym.load('BreakoutDeterministic-v4'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x_kELt70-xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_step = example_environment.reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQZ8yQts1B1f",
        "colab_type": "code",
        "outputId": "b9f0bed6-4672-4936-ef30-8087f401cdbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "random_policy.action(time_step)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int64, numpy=array([3])>, state=(), info=())"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tgjg3cY1DVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@test {\"skip\": true}\n",
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "  total_return = 0.0\n",
        "  for _ in range(num_episodes):\n",
        "\n",
        "    time_step = environment.reset()\n",
        "    episode_return = 0.0\n",
        "\n",
        "    while not time_step.is_last():\n",
        "      action_step = policy.action(time_step)\n",
        "      time_step = environment.step(action_step.action)\n",
        "      episode_return += time_step.reward\n",
        "    total_return += episode_return\n",
        "\n",
        "  avg_return = total_return / num_episodes\n",
        "  return avg_return.numpy()[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDyd4F2W1KlQ",
        "colab_type": "code",
        "outputId": "809d6730-8bcc-40ad-cadc-a266bf4f2366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "compute_avg_return(eval_env, random_policy, num_eval_episodes)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpYZvAXh1RpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "    data_spec=agent.collect_data_spec,\n",
        "    batch_size=train_env.batch_size,\n",
        "    max_length=replay_buffer_max_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG4_lEUj1cqR",
        "colab_type": "code",
        "outputId": "d3d812b1-1857-4844-976f-efeeda8778a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "agent.collect_data_spec"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Trajectory(step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), observation=BoundedTensorSpec(shape=(210, 160, 3), dtype=tf.uint8, name='observation', minimum=array(0, dtype=uint8), maximum=array(255, dtype=uint8)), action=BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0), maximum=array(3)), policy_info=(), next_step_type=TensorSpec(shape=(), dtype=tf.int32, name='step_type'), reward=TensorSpec(shape=(), dtype=tf.float32, name='reward'), discount=BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-8aQ5OA1f4h",
        "colab_type": "code",
        "outputId": "248e47eb-db2a-4ddb-a9dd-79ce827aaf78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "agent.collect_data_spec._fields"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('step_type',\n",
              " 'observation',\n",
              " 'action',\n",
              " 'policy_info',\n",
              " 'next_step_type',\n",
              " 'reward',\n",
              " 'discount')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJJa8reJ1ozm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@test {\"skip\": true}\n",
        "def collect_step(environment, policy, buffer):\n",
        "  time_step = environment.current_time_step()\n",
        "  action_step = policy.action(time_step)\n",
        "  next_time_step = environment.step(action_step.action)\n",
        "  traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
        "\n",
        "  # Add trajectory to the replay buffer\n",
        "  buffer.add_batch(traj)\n",
        "\n",
        "def collect_data(env, policy, buffer, steps):\n",
        "  for _ in range(steps):\n",
        "    collect_step(env, policy, buffer)\n",
        "\n",
        "collect_data(train_env, random_policy, replay_buffer, steps=100)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akLTW8Bu1py1",
        "colab_type": "code",
        "outputId": "e645fadd-983f-4b50-c75d-fcdfd7f5b8d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Dataset generates trajectories with shape [Bx2x...]\n",
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3, \n",
        "    sample_batch_size=batch_size, \n",
        "    num_steps=2).prefetch(3)\n",
        "\n",
        "\n",
        "dataset"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: (Trajectory(step_type=(64, 2), observation=(64, 2, 210, 160, 3), action=(64, 2), policy_info=(), next_step_type=(64, 2), reward=(64, 2), discount=(64, 2)), BufferInfo(ids=(64, 2), probabilities=(64,))), types: (Trajectory(step_type=tf.int32, observation=tf.uint8, action=tf.int64, policy_info=(), next_step_type=tf.int32, reward=tf.float32, discount=tf.float32), BufferInfo(ids=tf.int64, probabilities=tf.float32))>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coTOGhKz1vG6",
        "colab_type": "code",
        "outputId": "e52b984c-a7db-4569-e0c6-1a288a6e7a03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "iterator = iter(dataset)\n",
        "\n",
        "print(iterator)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7efeec8fc668>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGzV2NLD10t1",
        "colab_type": "code",
        "outputId": "73173235-35a4-4e80-a53d-da2d9883cee1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#@test {\"skip\": true}\n",
        "try:\n",
        "  %%time\n",
        "except:\n",
        "  pass\n",
        "\n",
        "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "for _ in range(num_iterations):\n",
        "\n",
        "  # Collect a few steps using collect_policy and save to the replay buffer.\n",
        "  for _ in range(collect_steps_per_iteration):\n",
        "    collect_step(train_env, agent.collect_policy, replay_buffer)\n",
        "\n",
        "  # Sample a batch of data from the buffer and update the agent's network.\n",
        "  experience, unused_info = next(iterator)\n",
        "  train_loss = agent.train(experience).loss\n",
        "\n",
        "  step = agent.train_step_counter.numpy()\n",
        "\n",
        "  if step % log_interval == 0:\n",
        "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "  if step % eval_interval == 0:\n",
        "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "    returns.append(avg_return)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
            "Wall time: 7.63 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_Md7vDUIZYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iterations = range(0, num_iterations + 1, eval_interval)\n",
        "plt.plot(iterations, returns)\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylim(top=250)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1UU-areIuF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embed_mp4(filename):\n",
        "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
        "  video = open(filename,'rb').read()\n",
        "  b64 = base64.b64encode(video)\n",
        "  tag = '''\n",
        "  <video width=\"640\" height=\"480\" controls>\n",
        "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
        "  Your browser does not support the video tag.\n",
        "  </video>'''.format(b64.decode())\n",
        "\n",
        "  return IPython.display.HTML(tag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNUZlNuxI0VF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_policy_eval_video(policy, filename, num_episodes=5, fps=30):\n",
        "  filename = filename + \".mp4\"\n",
        "  with imageio.get_writer(filename, fps=fps) as video:\n",
        "    for _ in range(num_episodes):\n",
        "      time_step = eval_env.reset()\n",
        "      video.append_data(eval_py_env.render())\n",
        "      while not time_step.is_last():\n",
        "        action_step = policy.action(time_step)\n",
        "        time_step = eval_env.step(action_step.action)\n",
        "        video.append_data(eval_py_env.render())\n",
        "  return embed_mp4(filename)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "create_policy_eval_video(agent.policy, \"trained-agent\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}